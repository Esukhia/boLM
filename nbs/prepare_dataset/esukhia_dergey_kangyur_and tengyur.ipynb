{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'P000001'...\n",
      "remote: Enumerating objects: 625, done.\u001b[K\n",
      "remote: Total 625 (delta 0), reused 0 (delta 0), pack-reused 625\u001b[K\n",
      "Receiving objects: 100% (625/625), 48.99 MiB | 31.65 MiB/s, done.\n",
      "Resolving deltas: 100% (198/198), done.\n",
      "Checking out files: 100% (517/517), done.\n",
      "Cloning into 'P000002'...\n",
      "remote: Enumerating objects: 6, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 1291 (delta 0), reused 0 (delta 0), pack-reused 1285\u001b[K\n",
      "Receiving objects: 100% (1291/1291), 133.54 MiB | 30.80 MiB/s, done.\n",
      "Resolving deltas: 100% (413/413), done.\n",
      "Checking out files: 100% (1068/1068), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/OpenPecha/P000001.git\n",
    "!git clone https://github.com/OpenPecha/P000002.git\n",
    "\n",
    "!du -sh ./P000001\n",
    "!du -sh ./P000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbd-colab\n",
      "  Downloading https://files.pythonhosted.org/packages/36/65/a42de9bcc11ffddc20ae8fa2eb2e09f3b7e3d15eb12cb24f95d296d9e880/nbd_colab-0.0.10-py3-none-any.whl\n",
      "Collecting nbdev\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c2/2631b32810211b6be5b17aff8db7135a8f29ff2a09a397cd9efbba490d48/nbdev-0.2.17-py3-none-any.whl (44kB)\n",
      "\r\u001b[K     |███████▎                        | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20kB 25.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
      "\u001b[?25hCollecting fastcore\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/b5/aed836ce5b16ea1088a5d1a41d400bc051abf90bbef58bb74d8fd01a76af/fastcore-0.1.16-py3-none-any.whl\n",
      "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev->nbd-colab) (5.0.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nbdev->nbd-colab) (3.13)\n",
      "Collecting fastscript\n",
      "  Downloading https://files.pythonhosted.org/packages/55/0e/ecdc0213646bc82986884121109a38b50bbc2cd2c491bbbfdc7ae39228e3/fastscript-0.1.4-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nbdev->nbd-colab) (20.3)\n",
      "Requirement already satisfied: nbconvert>=5.6.1 in /usr/local/lib/python3.6/dist-packages (from nbdev->nbd-colab) (5.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->nbd-colab) (1.18.2)\n",
      "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->nbd-colab) (0.7)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->nbd-colab) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->nbd-colab) (2.6.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->nbd-colab) (4.6.3)\n",
      "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->nbd-colab) (4.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->nbdev->nbd-colab) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->nbdev->nbd-colab) (2.4.7)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (0.6.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (2.1.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (2.11.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (3.1.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->nbd-colab) (0.8.4)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat>=4.4.0->nbdev->nbd-colab) (4.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.6.1->nbdev->nbd-colab) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.6.1->nbdev->nbd-colab) (0.5.1)\n",
      "Installing collected packages: fastscript, nbdev, fastcore, nbd-colab\n",
      "Successfully installed fastcore-0.1.16 fastscript-0.1.4 nbd-colab-0.0.10 nbdev-0.2.17\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip install nbd-colab\n",
    "\n",
    "from nbd_colab import *\n",
    "\n",
    "drive_setup()\n",
    "home_dir()\n",
    "\n",
    "repo_name = 'bonltk'\n",
    "change_dir(f'/content/drive/My Drive/Notebooks/Esukhia/{repo_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install botok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#from botok import WordTokenizer, sentence_tokenizer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_paths = [Path('/content/P000001'), Path('/content/P000002')]\n",
    "\n",
    "data_path = Path('.bonltk/data/corpora/esukhia-dergey-katen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer('POS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(text, steps=[(' ', '_'), ('*', ''), ('(', ''), (')', ''), ('[', ''), (']', '')]):\n",
    "    for f, t in steps:\n",
    "        text = text.replace(f, t)\n",
    "    return text \n",
    "\n",
    "def get_sentences(text):\n",
    "        text = text.replace('\\n', '')\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        sentences_tok = sentence_tokenizer(tokens)\n",
    "        sentences = [' '.join([post_process(tok.text) for tok in sent[1]]).strip() for sent in sentences_tok]\n",
    "        return sentences\n",
    "\n",
    "def convert_to_sentence_per_line(paths, out_path):\n",
    "    n_sents = 0\n",
    "    for path in tqdm(paths):\n",
    "        base_path = path/f'{path.name}.opf'/'base'\n",
    "        out_path = data_path/path.name\n",
    "        out_path.mkdir(exist_ok=True, parents=True)\n",
    "        for vol_fn in tqdm(list(base_path.iterdir())):\n",
    "            vol_out_fn = out_path/vol_fn.name\n",
    "            if vol_out_fn.is_file(): continue\n",
    "            # read text\n",
    "            text = vol_fn.read_text()\n",
    "\n",
    "            # segment text ot sentences\n",
    "            sentences = get_sentences(text)\n",
    "            \n",
    "            # save the sentences\n",
    "            vol_out_fn.write_text('\\n'.join(sentences))\n",
    "\n",
    "            n_sents += len(sentences)\n",
    "\n",
    "    print(f'[INFO] Courpus contains {n_sents} sentences.')\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = convert_to_sentence_per_line(source_paths, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_post_process(path):\n",
    "    steps = [(' ', '@'), ('_', ' '), ('@', '_'), ('*', ''), ('(', ''), (')', ''), ('[', ''), (']', '')]\n",
    "    for path in tqdm(path.iterdir()):\n",
    "        if path.is_file(): continue\n",
    "        for vol_fn in tqdm(list(path.iterdir())):\n",
    "            text = vol_fn.read_text()\n",
    "            vol_fn.write_text(post_process(text, steps=steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41ef015c357426fa5945e898146432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24f14c805d48f5928f410f8d2491f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=103), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366e813560de4533a0e46165c3f2eacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=213), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_post_process(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare pickle file size\n",
    "\n",
    ".txt and .pkl of text file has exact same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = data_path/f'all-{data_path.name}.txt'\n",
    "out_fn = data_path/f'all-{data_path.name}.pkl' \n",
    "text = fn.read_text()\n",
    "pickle.dump(text, out_fn.open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'༄༅། །འདུལ་བ་ང་བཞུགས་སོ།།༄༅༅། །\\nའདུལ་བ་གཞི། བམ་པོ་བརྒྱད་བཅུ་གསུམ་པ། གཟིགས་ནས་\\nཀྱང་ཁ་ལོ་སྒྱུར་བ་ལ་གསུང'"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_text = pickle.load(out_fn.open('rb'))\n",
    "pkl_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
